{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noxthot/mambaforge/envs/mlvapto/lib/python3.10/site-packages/petastorm/spark/spark_dataset_converter.py:28: FutureWarning: pyarrow.LocalFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
      "  from pyarrow import LocalFileSystem\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import ccc\n",
    "import utils\n",
    "import utils_plots\n",
    "import utils_shap\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_MODE = 1\n",
    "GRADIENT_EXPLAINER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmsubdir = f'targetmode_{TARGET_MODE}'\n",
    "model_root_tm_path = os.path.join(ccc.MODEL_ROOT_PATH, tmsubdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a95beaa68b143e38de4e0fade136a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Choose a model:', options=('2023_10_10__09-55_1D_CNN', '2023_08_24__15-54__fc_testyear_2â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modeldirs = os.listdir(model_root_tm_path)\n",
    "modeldirs.sort(reverse=True)\n",
    "\n",
    "wmodel = widgets.Dropdown(\n",
    "                    options=modeldirs,\n",
    "                    value=modeldirs[0],\n",
    "                    description='Choose a model:',\n",
    ")\n",
    "\n",
    "display(wmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m shaps\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m      5\u001b[0m shaps \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m shaps \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.test.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      7\u001b[0m wshaps \u001b[38;5;241m=\u001b[39m widgets\u001b[38;5;241m.\u001b[39mDropdown(\n\u001b[1;32m      8\u001b[0m                     options\u001b[38;5;241m=\u001b[39mshaps,\n\u001b[0;32m----> 9\u001b[0m                     value\u001b[38;5;241m=\u001b[39m\u001b[43mshaps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     10\u001b[0m                     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChoose a model:\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m display(wshaps)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "modelpath = os.path.join(model_root_tm_path, wmodel.value)\n",
    "shaps = os.listdir(modelpath)\n",
    "shaps.sort()\n",
    "\n",
    "shaps = [x for x in shaps if x.endswith(\".test.json\")]\n",
    "\n",
    "wshaps = widgets.Dropdown(\n",
    "                    options=shaps,\n",
    "                    value=shaps[0],\n",
    "                    description='Choose a model:',\n",
    ")\n",
    "\n",
    "display(wshaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(modelpath, wshaps.value), 'r') as f:\n",
    "    test_scores_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradexplain_postfix = \"_gradientexplainer\" if GRADIENT_EXPLAINER else \"\"\n",
    "\n",
    "_, model_name = utils.load_model(os.path.join(f'targetmode_{TARGET_MODE}', wmodel.value), torch.device(\"cpu\"), test_scores_json[\"epoch\"])\n",
    "\n",
    "shap_path = os.path.join(modelpath, test_scores_json[\"prefix_dirs\"] + f\"_shap_parquet{gradexplain_postfix}\")\n",
    "df_path = os.path.join(modelpath, test_scores_json[\"test_pickle\"])\n",
    "\n",
    "dd = pd.read_pickle(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_save_path = os.path.join(modelpath, test_scores_json[\"prefix_dirs\"] + f\"_shap_plots{gradexplain_postfix}\")\n",
    "\n",
    "if vis_save_path != \"\":\n",
    "    if not os.path.isdir(vis_save_path):\n",
    "        os.makedirs(vis_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_threshold = utils.getVeryConfidentThreshold(test_scores_json[\"used_threshold\"])\n",
    "dd_transf = dd\n",
    "\n",
    "dd_transf.loc[:, \"pred_class\"] = np.where(dd_transf[\"output\"] > test_scores_json[\"used_threshold\"], \"pred_flash\", \"pred_no_flash\")\n",
    "dd_transf.loc[:, \"real_class\"] = np.where(dd_transf[\"target\"] > 0.5, \"real_flash\", \"real_no_flash\")  # target col only contains 0s and 1s.\n",
    "\n",
    "dd_transf.loc[:, 'cat'] = np.select(\n",
    "    [\n",
    "        (dd_transf['pred_class'] == \"pred_flash\") & (dd_transf['real_class'] == \"real_flash\") & (dd_transf[\"output\"] < vc_threshold), \n",
    "        (dd_transf['pred_class'] == \"pred_flash\") & (dd_transf['real_class'] == \"real_flash\") & (dd_transf[\"output\"] >= vc_threshold), \n",
    "        (dd_transf['pred_class'] == \"pred_no_flash\") & (dd_transf['real_class'] == \"real_flash\"), \n",
    "        (dd_transf['pred_class'] == \"pred_flash\") & (dd_transf['real_class'] == \"real_no_flash\"), \n",
    "        (dd_transf['pred_class'] == \"pred_no_flash\") & (dd_transf['real_class'] == \"real_no_flash\"), \n",
    "    ], \n",
    "    [\n",
    "        'TP_LC', \n",
    "        'TP_VC',\n",
    "        'FN',\n",
    "        'FP',\n",
    "        'TN',\n",
    "    ], \n",
    "    default='ERROR'\n",
    ")\n",
    "\n",
    "dd_transf.loc[:, 'cluster'] = np.select(\n",
    "    [dd_transf['cat'] == \"TP_LC\", dd_transf['cat'] == \"TP_VC\", dd_transf['cat'] == \"FN\", dd_transf['cat'] == \"FP\", dd_transf['cat'] == \"TN\",],\n",
    "    [0, 1, 2, 3, 4,],\n",
    "    default=-1\n",
    ")\n",
    "\n",
    "dd_transf = dd_transf.rename(columns={\"output\": \"pred_score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(dd_transf.query(\"cat in ['TP_LC', 'TP_VC']\")['pred_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(dd_transf.query(\"cat in ['TP_LC', 'TP_VC']\")['pred_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(modelpath, 'data_cfg.json'), 'r') as f:\n",
    "    config_data = json.load(f)\n",
    "\n",
    "with open(os.path.join(modelpath, 'model_cfg.json'), 'r') as f:\n",
    "    config_model = json.load(f)\n",
    "\n",
    "traincols = config_model[\"traincols\"] if (\"traincols\" in config_model) else utils.get_train_cols(config_data[\"datamode\"])\n",
    "\n",
    "cols = []\n",
    "\n",
    "for col in ccc.LVL_COLS_ETL:\n",
    "    for lvl_idx in range(74):\n",
    "        lvl = 64 + lvl_idx\n",
    "        cols.append(f\"{col}_lvl{lvl}\")\n",
    "\n",
    "cols.extend(ccc.INDEX_COLS)\n",
    "cols.extend(traincols)\n",
    "\n",
    "cols = list(set(cols))\n",
    "print(\"Load test data into spark df\", flush=True)\n",
    "test_package = utils.get_testdf_spark(config_data, cols, None, use_months=test_scores_json[\"used_months\"], test_scores_config=test_scores_json)\n",
    "sparkdd_test = test_package[\"data\"].drop(\"features\").drop(\"label\")\n",
    "\n",
    "print(\"Convert test data (excluding TNs) into spark df\", flush=True)\n",
    "spark = utils.getsparksession()\n",
    "sparkdd = spark.createDataFrame(dd_transf.query(\"cat != 'TN'\"))\n",
    "\n",
    "print(\"Join the two dfs\")\n",
    "sparkdd = utils.joinDataframes(sparkdd, sparkdd_test)\n",
    "\n",
    "print(\"Convert to pandas df\")\n",
    "dd_enriched = sparkdd.toPandas()\n",
    "\n",
    "print(\"Free memory\")\n",
    "del sparkdd\n",
    "del sparkdd_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (dd_enriched[\"cat\"] == 'TP_VC') | (dd_enriched[\"cat\"] == 'TP_LC')  # we only cluster for true positives\n",
    "dd_tp = dd_enriched.loc[mask, :]\n",
    "dd_fx = dd_enriched.loc[~mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_tp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(dd_tp), len(dd_fx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_smallest_cl = dd_enriched['cluster'].value_counts().min()\n",
    "dd_enriched['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoh_cols = [col for col in dd_enriched.columns if col.startswith(\"geoh_\")]\n",
    "\n",
    "df_many_cases = dd_enriched[ccc.INDEX_COLS + geoh_cols + ['cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_many_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_many_cases_sampled = df_many_cases.groupby('cluster').sample(size_of_smallest_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_many_cases_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dshap = pd.read_parquet(shap_path) ## serves as test file\n",
    "dshap.rename(columns={utils_shap.colname_meta_infix(col) : col for col in ccc.INDEX_COLS}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_many_cases_shap = utils.joinDataframes(df_many_cases_sampled, dshap)\n",
    "df_many_cases_shap.drop([\"flash_meta\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casestudies\n",
    "case1 = {  \n",
    "        \"lon\" : 15,\n",
    "        \"lat\" : 45.25,\n",
    "        \"day\" : 11,\n",
    "        \"month\" : 6,\n",
    "        \"hour\" : 19,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case2 = {  \n",
    "        \"lon\" : 9.25,\n",
    "        \"lat\" : 48.25,\n",
    "        \"day\" : 12,\n",
    "        \"month\" : 7,\n",
    "        \"hour\" : 19,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case3 = {  \n",
    "        \"lon\" : 10.5,\n",
    "        \"lat\" : 47.5,\n",
    "        \"day\" : 12,\n",
    "        \"month\" : 7,\n",
    "        \"hour\" : 22,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case4 = {  \n",
    "        \"lon\" : 8.75,\n",
    "        \"lat\" : 46.25,\n",
    "        \"day\" : 14,\n",
    "        \"month\" : 7,\n",
    "        \"hour\" : 21,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case5 = {  \n",
    "        \"lon\" : 16.75,\n",
    "        \"lat\" : 48.0,\n",
    "        \"day\" : 1,\n",
    "        \"month\" : 7,\n",
    "        \"hour\" : 21,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case6 = {  \n",
    "        \"lon\" : 11.25,\n",
    "        \"lat\" : 49.75,\n",
    "        \"day\" : 3,\n",
    "        \"month\" : 6,\n",
    "        \"hour\" : 18,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case7 = {  \n",
    "        \"lon\" : 16.75,\n",
    "        \"lat\" : 46.75,\n",
    "        \"day\" : 24,\n",
    "        \"month\" : 8,\n",
    "        \"hour\" : 17,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case8 = {  \n",
    "        \"lon\" : 13.5,\n",
    "        \"lat\" : 47.0,\n",
    "        \"day\" : 1,\n",
    "        \"month\" : 8,\n",
    "        \"hour\" : 19,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case9 = {  \n",
    "        \"lon\" : 13.5,\n",
    "        \"lat\" : 48.5,\n",
    "        \"day\" : 10,\n",
    "        \"month\" : 6,\n",
    "        \"hour\" : 20,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case10 = {  \n",
    "        \"lon\" : 16.0,\n",
    "        \"lat\" : 47.0,\n",
    "        \"day\" : 27,\n",
    "        \"month\" : 6,\n",
    "        \"hour\" : 19,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case11 = {  \n",
    "        \"lon\" : 16.0,\n",
    "        \"lat\" : 45.5,\n",
    "        \"day\" : 27,\n",
    "        \"month\" : 7,\n",
    "        \"hour\" : 19,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case12 = {  \n",
    "        \"lon\" : 15,\n",
    "        \"lat\" : 47.25,\n",
    "        \"day\" : 20,\n",
    "        \"month\" : 6,\n",
    "        \"hour\" : 20,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case13 = {  \n",
    "        \"lon\" : 11.25,\n",
    "        \"lat\" : 49.75,\n",
    "        \"day\" : 3,\n",
    "        \"month\" : 6,\n",
    "        \"hour\" : 18,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case14 = {  \n",
    "        \"lon\" : 10.25,\n",
    "        \"lat\" : 46.25,\n",
    "        \"day\" : 24,\n",
    "        \"month\" : 7,\n",
    "        \"hour\" : 21,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "case15 = {  \n",
    "        \"lon\" : 11.0,\n",
    "        \"lat\" : 48.0,\n",
    "        \"day\" : 10,\n",
    "        \"month\" : 6,\n",
    "        \"hour\" : 16,\n",
    "        \"year\" : 2019,\n",
    "}\n",
    "\n",
    "only_show_case = None  # choose a case you are interested in; otherwise set to None\n",
    "\n",
    "df_shap_to_plot = df_many_cases_shap if only_show_case is None else df_many_cases_shap.query(f\"longitude == {only_show_case['lon']} and latitude == {only_show_case['lat']} and day == {only_show_case['day']} and month == {only_show_case['month']} and hour == {only_show_case['hour']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for debugging to quickly reload utils_plots.py\n",
    "import importlib\n",
    "importlib.reload(utils_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptype = \"q50\"  # can be mult, q50, q95\n",
    "use_cache = True\n",
    "separate_clusters = False\n",
    "plot_clusters = {\n",
    "                    0: 'TP less confident',\n",
    "#                    1: 'TP very confident',\n",
    "#                    2: 'FN',\n",
    "                    3: 'FP',\n",
    "#                    4: 'TN',\n",
    "                }\n",
    "\n",
    "only_show_cols = []\n",
    "#only_show_cols = [\"ciwc\", \"cswc\"]\n",
    "\n",
    "y_axis = \"geopotential_altitude\"  # level, geopotential_altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_plots.plot_many_profiles(df_shap_to_plot, \"feature\", config_data[\"datamode\"], ptype=ptype, y_axis=y_axis, separate_clusters=separate_clusters, save_path=vis_save_path, use_cache=use_cache, plot_clusters=plot_clusters, only_show_cols=only_show_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils_plots.plot_many_profiles(df_many_cases_shap, \"shap\", config_data[\"datamode\"], ptype=ptype, y_axis=y_axis, separate_clusters=separate_clusters, save_path=vis_save_path, use_cache=use_cache, plot_clusters=plot_clusters, only_show_cols=only_show_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucols = [\"longitude\", \"latitude\", \"year\", \"month\", \"day\", \"hour\", \"cbh\", \"cth\", \"cluster\"]\n",
    "df_cbh_cth_grouped = df_many_cases.reset_index()[ucols].groupby(ucols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbh_ls = []\n",
    "cth_ls = []\n",
    "cluster_ls = []\n",
    "\n",
    "for group, _ in df_cbh_cth_grouped:\n",
    "    cbh_ls.append(group[ucols.index(\"cbh\")])\n",
    "    cth_ls.append(group[ucols.index(\"cth\")])\n",
    "    cluster_ls.append(group[ucols.index(\"cluster\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cbh_cth = pd.DataFrame({\"cbh\" : cbh_ls, \"cth\" : cth_ls, \"cluster\" : cluster_ls})\n",
    "df_cbh_cth[\"ch\"] = df_cbh_cth[\"cth\"] - df_cbh_cth[\"cbh\"]\n",
    "df_cbh_cth = df_cbh_cth[df_cbh_cth[\"cluster\"].isin(plot_clusters.keys())]\n",
    "df_cbh_cth[\"cluster_labels\"] = df_cbh_cth[\"cluster\"].replace(plot_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette([utils_plots.CLUSTER_COLORS[col] for col in plot_clusters.keys()] if len(plot_clusters) > 0 else utils_plots.CLUSTER_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_elements = [Patch(color=utils_plots.CLUSTER_COLORS[key], label=plot_clusters[key]) for key in plot_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_medians = df_cbh_cth.groupby(\"cluster\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plt.figure(figsize=(8, 15))\n",
    "graph = sns.violinplot(data=df_cbh_cth, x=\"cluster\", y=\"cth\", fliersize=3, palette=palette, cut=0)\n",
    "g.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(0.9, 0.5))\n",
    "\n",
    "for idx in plot_clusters.keys():\n",
    "    graph.axhline(cloud_medians.query(f\"cluster == {idx}\")[\"cth\"].values[0], color=utils_plots.CLUSTER_COLORS[idx])\n",
    "\n",
    "ofile = os.path.join(vis_save_path, f\"cth_violinplot\")\n",
    "g.savefig(f\"{ofile}.pdf\")\n",
    "g.savefig(f\"{ofile}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plt.figure(figsize=(8, 15))\n",
    "graph = sns.violinplot(data=df_cbh_cth, x=\"cluster\", y=\"cbh\", fliersize=3, palette=palette, cut=0)\n",
    "g.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(0.9, 0.5))\n",
    "\n",
    "for idx in plot_clusters.keys():\n",
    "    graph.axhline(cloud_medians.query(f\"cluster == {idx}\")[\"cbh\"].values[0], color=utils_plots.CLUSTER_COLORS[idx])\n",
    "\n",
    "ofile = os.path.join(vis_save_path, f\"violinplot_cbh\")\n",
    "g.savefig(f\"{ofile}.pdf\")\n",
    "g.savefig(f\"{ofile}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plt.figure(figsize=(8, 15))\n",
    "graph = sns.violinplot(data=df_cbh_cth, x=\"cluster\", y=\"ch\", fliersize=3, palette=palette, cut=0)\n",
    "g.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(0.9, 0.5))\n",
    "\n",
    "for idx in plot_clusters.keys():\n",
    "    graph.axhline(cloud_medians.query(f\"cluster == {idx}\")[\"ch\"].values[0], color=utils_plots.CLUSTER_COLORS[idx])\n",
    "\n",
    "ofile = os.path.join(vis_save_path, f\"violinplot_ch\")\n",
    "g.savefig(f\"{ofile}.pdf\")\n",
    "g.savefig(f\"{ofile}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f77099b03e26f5f2a39d729b0e5ff7cce62b3e0b846f69c8115517d984996de7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
